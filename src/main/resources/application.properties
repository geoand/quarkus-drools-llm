quarkus.log.level=INFO

quarkus.langchain4j.ollama.chat-model.model-id=mistral
quarkus.langchain4j.ollama.chat-model.temperature=0.1
quarkus.langchain4j.ollama.timeout=180s
quarkus.langchain4j.ollama.log-requests=true
quarkus.langchain4j.ollama.log-responses=true

quarkus.langchain4j.ollama.hotmodel.chat-model.model-id=mistral
quarkus.langchain4j.ollama.hotmodel.chat-model.temperature=1.0
quarkus.langchain4j.ollama.hotmodel.timeout=180s
quarkus.langchain4j.ollama.hotmodel.log-requests=true
quarkus.langchain4j.ollama.hotmodel.log-responses=true
